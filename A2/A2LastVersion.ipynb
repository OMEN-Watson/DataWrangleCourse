{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "education_dataset = pd.read_csv('/mnt/data/data_wrangling_education_2024_u7568823.csv')\n",
    "medical_dataset = pd.read_csv('/mnt/data/data_wrangling_medical_2024_u7568823.csv')\n",
    "\n",
    "# Step 1: Merge the two datasets on the common attribute (SSN)\n",
    "merged_dataset = pd.merge(education_dataset, medical_dataset, on='ssn', how='outer', suffixes=('_education', '_medical'))\n",
    "\n",
    "# Step 2: Data Cleaning Tasks\n",
    "\n",
    "# 1. Remove Duplicates based on 'ssn' and key attributes\n",
    "merged_dataset.drop_duplicates(subset='ssn', keep='last', inplace=True)\n",
    "\n",
    "# 2. Handle Missing Values\n",
    "# For simplicity, let's fill categorical missing values with 'Unknown' and numerical missing values with the median.\n",
    "categorical_cols = merged_dataset.select_dtypes(include=['object']).columns\n",
    "numerical_cols = merged_dataset.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Fill missing values\n",
    "merged_dataset[categorical_cols] = merged_dataset[categorical_cols].fillna('Unknown')\n",
    "merged_dataset[numerical_cols] = merged_dataset[numerical_cols].fillna(merged_dataset[numerical_cols].median())\n",
    "\n",
    "# 3. Detect and handle inconsistent values (e.g., negative values in 'salary' and 'weight')\n",
    "merged_dataset['salary'] = merged_dataset['salary'].apply(lambda x: x if x >= 0 else merged_dataset['salary'].median())\n",
    "merged_dataset['weight'] = merged_dataset['weight'].apply(lambda x: x if x >= 0 else merged_dataset['weight'].median())\n",
    "\n",
    "# 4. Imputation for values where it makes sense\n",
    "# For instance, calculate BMI from weight and height if BMI is missing\n",
    "def calculate_bmi(row):\n",
    "    if pd.isnull(row['bmi']) and not pd.isnull(row['weight']) and not pd.isnull(row['height']):\n",
    "        height_in_meters = row['height'] / 100\n",
    "        return row['weight'] / (height_in_meters ** 2)\n",
    "    return row['bmi']\n",
    "\n",
    "merged_dataset['bmi'] = merged_dataset.apply(calculate_bmi, axis=1)\n",
    "\n",
    "# Step 5: Handle Invalid Email and Phone entries\n",
    "# Detect phone numbers in the email field and vice versa\n",
    "import re\n",
    "\n",
    "def looks_like_phone(value):\n",
    "    if pd.isnull(value):\n",
    "        return False\n",
    "    digits_only = re.sub(r'\\D', '', str(value))  # Remove non-digit characters\n",
    "    return len(digits_only) >= 10  # Assume phone numbers have at least 10 digits\n",
    "\n",
    "def looks_like_email(value):\n",
    "    if pd.isnull(value):\n",
    "        return False\n",
    "    return re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', str(value)) is not None\n",
    "\n",
    "# Correct email and phone based on validation\n",
    "merged_dataset.loc[merged_dataset['email'].apply(looks_like_phone), 'email'] = 'Invalid Email'\n",
    "merged_dataset.loc[merged_dataset['phone'].apply(looks_like_email), 'phone'] = 'Invalid Phone'\n",
    "\n",
    "# Output the cleaned dataset to a CSV\n",
    "output_file = '/mnt/data/cleaned_merged_dataset.csv'\n",
    "merged_dataset.to_csv(output_file, index=False)\n",
    "\n",
    "output_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output duplicate ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "education_df = pd.read_csv('files/lastVersion/merged_education_medical.csv')\n",
    "\n",
    "# Filter rows with duplicate SSNs\n",
    "duplicate_ssn_education = education_df[education_df.duplicated(subset='ssn', keep=False)]\n",
    "\n",
    "# Save the duplicate entries to a new CSV file\n",
    "duplicate_ssn_education.to_csv('files/lastVersion/duplicate_mergeDataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge 2 data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ssn first_name_education middle_name_education last_name_education  \\\n",
      "0  g180519599              matthew              mcfarrin             lovette   \n",
      "1  e141846696                 john                   NaN              stultz   \n",
      "2  h140232568               carrie                  hall              greene   \n",
      "3  c129535181                diane                     j             gunther   \n",
      "4  e145580195               joseph                 vance          fitzgerald   \n",
      "\n",
      "  gender_education  current_age birth_date_education  \\\n",
      "0                m           77            5/12/1943   \n",
      "1                m           16             6/9/2004   \n",
      "2                f           30           17/10/1990   \n",
      "3                f           34           25/11/1986   \n",
      "4                m           54            23/3/1966   \n",
      "\n",
      "               street_address_education suburb_education  postcode_education  \\\n",
      "0    36  zouch  street  edward  street             young              2594.0   \n",
      "1           533  north  road  longford          mortlake              3272.0   \n",
      "2       258  lyons  street  mater  dei         westcourt              4870.0   \n",
      "3     25  ney  road  hillcrest  garden          capalaba              4157.0   \n",
      "4   81  invermay  road  invermay  farm           monbulk              3793.0   \n",
      "\n",
      "   ...               email_medical marital_status height weight bmi  \\\n",
      "0  ...       lovette90@hotmail.com        married    174    104  34   \n",
      "1  ...          john87@mail.com.au            NaN    162     74  28   \n",
      "2  ...      greene.carrie@mail.com    not-married    199     56  14   \n",
      "3  ...            diane67@mail.com    not-married    170     69  23   \n",
      "4  ...  joseph.fitzgerald@mail.com    not-married    169    139  48   \n",
      "\n",
      "   blood_pressure cholesterol_level  smoking_status  \\\n",
      "0              71               176               0   \n",
      "1              86               247               0   \n",
      "2              78               260               0   \n",
      "3              70               212               1   \n",
      "4              81               193               0   \n",
      "\n",
      "                   clinical_notes  consultation_timestamp  \n",
      "0                      trunk-rash  2019-12-20t23:56+00:00  \n",
      "1                        coughing  2019-11-23t19:52+00:00  \n",
      "2                            fall  2016-07-05t13:27+00:00  \n",
      "3  cuts-and-abrasions-due-to-fall  2017-12-21t18:17+00:00  \n",
      "4                        coughing  2014-01-11t04:11+00:00  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into dataframes\n",
    "education_df = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "medical_df = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "\n",
    "# Drop the 'rec_id' column from both datasets before merging\n",
    "education_df_cleaned = education_df.drop(columns=['rec_id'])\n",
    "medical_df_cleaned = medical_df.drop(columns=['rec_id'])\n",
    "\n",
    "# Perform the merge based on the 'ssn' column, using an inner join\n",
    "merged_df = pd.merge(education_df_cleaned, medical_df_cleaned, on='ssn', suffixes=('_education', '_medical'))\n",
    "\n",
    "# Save the merged dataframe to a CSV file if needed\n",
    "merged_df.to_csv('files/lastVersion/merged_education_medical.csv', index=False)\n",
    "\n",
    "# Optionally, display the merged dataframe\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge newer first_name,middle_name,last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.read_csv('files/lastVersion/merged_education_medical.csv')\n",
    "\n",
    "# First, convert the timestamp columns to datetime to enable comparison\n",
    "merged_df['employment_timestamp'] = pd.to_datetime(merged_df['employment_timestamp'], errors='coerce')\n",
    "merged_df['consultation_timestamp'] = pd.to_datetime(merged_df['consultation_timestamp'], errors='coerce')\n",
    "\n",
    "# Define a function to keep the names based on the newer timestamp\n",
    "def choose_newer_name(row):\n",
    "    if pd.isnull(row['employment_timestamp']):\n",
    "        return row['first_name_medical'], row['middle_name_medical'], row['last_name_medical']\n",
    "    if pd.isnull(row['consultation_timestamp']):\n",
    "        return row['first_name_education'], row['middle_name_education'], row['last_name_education']\n",
    "    if row['consultation_timestamp'] > row['employment_timestamp']:\n",
    "        return row['first_name_medical'], row['middle_name_medical'], row['last_name_medical']\n",
    "    else:\n",
    "        return row['first_name_education'], row['middle_name_education'], row['last_name_education']\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df[['first_name', 'middle_name', 'last_name']] = merged_df.apply(\n",
    "    lambda row: pd.Series(choose_newer_name(row)), axis=1\n",
    ")\n",
    "\n",
    "# Drop the old columns with suffixes\n",
    "merged_df.drop(columns=['first_name_education', 'first_name_medical', \n",
    "                        'middle_name_education', 'middle_name_medical', \n",
    "                        'last_name_education', 'last_name_medical'], inplace=True)\n",
    "\n",
    "name_columns = ['first_name', 'middle_name', 'last_name']\n",
    "columns_order = ['ssn'] + name_columns + [col for col in merged_df.columns if col not in name_columns and col != 'ssn']\n",
    "\n",
    "# Reorder the columns\n",
    "merged_df = merged_df[columns_order]\n",
    "\n",
    "# Display the updated dataframe or save to a file if needed\n",
    "merged_df.to_csv('files/lastVersion//merged_names_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.read_csv('files/lastVersion/merged_names_dataset.csv')\n",
    "\n",
    "# Convert the timestamps to datetime format for comparison\n",
    "merged_df['employment_timestamp'] = pd.to_datetime(merged_df['employment_timestamp'], errors='coerce')\n",
    "merged_df['consultation_timestamp'] = pd.to_datetime(merged_df['consultation_timestamp'], errors='coerce')\n",
    "\n",
    "# Merge common attributes based on the most recent timestamp\n",
    "\n",
    "# Gender\n",
    "merged_df['gender'] = merged_df.apply(\n",
    "    lambda row: row['gender_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['gender_education'], axis=1)\n",
    "\n",
    "# Birth Date\n",
    "merged_df['birth_date'] = merged_df.apply(\n",
    "    lambda row: row['birth_date_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['birth_date_education'], axis=1)\n",
    "\n",
    "# Street Address\n",
    "merged_df['street_address'] = merged_df.apply(\n",
    "    lambda row: row['street_address_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['street_address_education'], axis=1)\n",
    "\n",
    "# Suburb\n",
    "merged_df['suburb'] = merged_df.apply(\n",
    "    lambda row: row['suburb_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['suburb_education'], axis=1)\n",
    "\n",
    "# Postcode\n",
    "merged_df['postcode'] = merged_df.apply(\n",
    "    lambda row: row['postcode_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['postcode_education'], axis=1)\n",
    "\n",
    "# State\n",
    "merged_df['state'] = merged_df.apply(\n",
    "    lambda row: row['state_education'] if row['employment_timestamp'] > row['consultation_timestamp'] else row['state_education'], axis=1)\n",
    "\n",
    "# Drop the old columns with suffixes from both datasets\n",
    "columns_to_drop = ['gender_education', 'birth_date_education', 'street_address_education', \n",
    "                   'suburb_education', 'postcode_education', 'state_education']\n",
    "merged_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Save the merged dataframe or display\n",
    "merged_df.to_csv('files/lastVersion/merged_common_attributes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_2780\\1512346858.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[59.9781 63.368  51.84   ... 95.83   59.2704 24.48  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[data['weight'] < 0, 'weight'] = data['bmi'] * (data['height_m'] ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ssn  age_at_consultation      medicare_number    marital_status  \\\n",
      "10     d165618464                   63   3242  66532  2  2            married   \n",
      "35     i150642589                   21   3385  37618  2  3            married   \n",
      "37     a145218863                   66   2112  80784  2  1            married   \n",
      "40     e193947611                   63   3631  95123  2  1        not-married   \n",
      "60     f199940301                   49   8951  39432  2  2        not-married   \n",
      "...           ...                  ...                  ...               ...   \n",
      "16764  g192756040                   51   2383  67740  2  1   married-de-facto   \n",
      "16778  h131934275                   28   5102  69110  1  1   married-de-facto   \n",
      "16785  e156647896                   19   2123  64651  1  2            married   \n",
      "16786  c161075281                   24   2642  10963  1  2        not-married   \n",
      "16789  g153285282                    9   1364  41872  1  3            married   \n",
      "\n",
      "       height  weight  bmi  blood_pressure  cholesterol_level  smoking_status  \\\n",
      "10        169    60.0   21              77                199               0   \n",
      "35        178    63.4   20              64                183               0   \n",
      "37        180    51.8   16              79                184               0   \n",
      "40        186   128.0   37              80                154               0   \n",
      "60        196   107.6   28              76                120               0   \n",
      "...       ...     ...  ...             ...                ...             ...   \n",
      "16764     194    90.3   24              77                161               0   \n",
      "16778     190   104.7   29              77                216               0   \n",
      "16785     185    95.8   28              63                107               0   \n",
      "16786     168    59.3   21              76                278               0   \n",
      "16789     120    24.5   17              76                147               0   \n",
      "\n",
      "       ... middle_name        last_name  gender  birth_date  \\\n",
      "10     ...    pauletta  hamburg-dibetta       f  11/06/1953   \n",
      "35     ...       wayne            rasco       f  18/09/1993   \n",
      "37     ...    rondrail          spruill       f  07/09/1944   \n",
      "40     ...    eleanore         braswell       f  26/06/1951   \n",
      "60     ...      parker           taylor       m  28/12/1963   \n",
      "...    ...         ...              ...     ...         ...   \n",
      "16764  ...        dean        wilkerson       m  23/04/1961   \n",
      "16778  ...    michelle         shepherd       f  07/06/1990   \n",
      "16785  ...       aleta           hodges       f  18/01/1996   \n",
      "16786  ...      agness          wilburn       m  23/11/1989   \n",
      "16789  ...         lee        alexander       f  19/09/2011   \n",
      "\n",
      "                                         street_address             suburb  \\\n",
      "10                  22  macgregor  street  the  grange              deakin   \n",
      "35                1  sovereign  point  court  apt  302           doncaster   \n",
      "37                    3  collins  close  masonic  vlge        lake  haven    \n",
      "40          260  main  road  lakeside  shoppng  centre      the  entrance    \n",
      "60                         18  sydney  road  inverness              mudgee   \n",
      "...                                                 ...                ...   \n",
      "16764   18  kalkaringi  street  kalkarindji  community    victoria  river    \n",
      "16778                          100  south  terrace  gc            adelaide   \n",
      "16785                  41  warburton  street  apmnt  9             chifley   \n",
      "16786                5  marsh  street  rowen  brafords       east  mackay    \n",
      "16789                  40  parap  road  finance  house              darwin   \n",
      "\n",
      "      postcode  state             phone                    email  \n",
      "10      2600.0    act   02  9028  4585    comtintofj@hotmail.com  \n",
      "35      3108.0    vic   03  3642  7767      rqonrrkhkh@gmail.com  \n",
      "37      2263.0    nsw   02  3226  1259    spruill.robert@aol.com  \n",
      "40      2261.0    nsw   02  5828  8064     eleanor37@hotmail.com  \n",
      "60      2850.0    nsw   02  4516  0031          taylor2@mail.com  \n",
      "...        ...    ...               ...                      ...  \n",
      "16764    800.0     nt   08  9136  5584                       NaN  \n",
      "16778   5000.0     sa   08  4788  4696         janice25@mail.com  \n",
      "16785   2324.0    nsw   02  5297  5183    sandra.hodges@mail.com  \n",
      "16786   4740.0    qld   07  6192  8740         wilburn11@aol.com  \n",
      "16789    800.0     nt               NaN  alexander.roy@gmail.com  \n",
      "\n",
      "[1648 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'file_path' with your actual file path)\n",
    "file_path = 'files/merged_dataset_Pro_maritalStatusAndSalary_imputation.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert height from cm to meters\n",
    "data['height_m'] = data['height'] / 100\n",
    "\n",
    "# Identify rows where weight is negative\n",
    "negative_weight_rows = data[data['weight'] < 0]\n",
    "\n",
    "# Correct the negative weights using the formula: weight = BMI * (height_m)^2\n",
    "data.loc[data['weight'] < 0, 'weight'] = data['bmi'] * (data['height_m'] ** 2)\n",
    "# Round the weight to 1 decimal place\n",
    "data['weight'] = data['weight'].round(1)\n",
    "# Drop the temporary 'height_m' column after correction\n",
    "data.drop(columns=['height_m'], inplace=True)\n",
    "\n",
    "# Save the corrected dataset back to a CSV file (optional)\n",
    "data.to_csv('merged_dataset_correctWeight.csv', index=False)\n",
    "\n",
    "# Display the corrected rows (optional)\n",
    "corrected_rows = data.loc[negative_weight_rows.index]\n",
    "print(corrected_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ssn  age_at_consultation      medicare_number    marital_status  \\\n",
      "6      i131945217                   29   4065  69117  1  2            married   \n",
      "19     g197247139                   27   7250  38940  2  1        not-married   \n",
      "27     d113054410                   30   6927  49080  1  2        not-married   \n",
      "47     c126684873                   57   2908  17186  2  1   married-de-facto   \n",
      "55     f166206248                   21   5065  40504  2  3        not-married   \n",
      "...           ...                  ...                  ...               ...   \n",
      "16764  g192756040                   51   2383  67740  2  1   married-de-facto   \n",
      "16766  b164323387                   54   6004  97272  2  2            married   \n",
      "16794  e155951170                   20   6298  84295  1  3        not-married   \n",
      "16801  a184970069                   48   8214  95221  2  1           divorced   \n",
      "16808  d136644076                    9   2399  36590  1  3        not-married   \n",
      "\n",
      "       height  weight  bmi  blood_pressure  cholesterol_level  smoking_status  \\\n",
      "6         187   115.0   32              74                187               0   \n",
      "19        186   141.0   40              77                146               0   \n",
      "27        167    63.0   22              69                217               0   \n",
      "47        198   100.0   25              72                284               0   \n",
      "55        190   115.0   31              67                194               0   \n",
      "...       ...     ...  ...             ...                ...             ...   \n",
      "16764     194    90.3   24              77                161               0   \n",
      "16766     196    58.0   15              75                139               0   \n",
      "16794     188   149.0   42              76                199               0   \n",
      "16801     181   114.0   34              78                162               0   \n",
      "16808     153    45.0   19              68                166               0   \n",
      "\n",
      "       ... middle_name  last_name  gender  birth_date  \\\n",
      "6      ...       ralph  mccormick       f  23/12/1983   \n",
      "19     ...     sentell       pike       f  04/07/1988   \n",
      "27     ...   alexander    meagher       m  17/09/1984   \n",
      "47     ...       odell        ang       f  31/05/1955   \n",
      "55     ...        john    loggins       f  04/01/1994   \n",
      "...    ...         ...        ...     ...         ...   \n",
      "16764  ...        dean  wilkerson       m  23/04/1961   \n",
      "16766  ...       leigh     yarbro       m  31/03/1961   \n",
      "16794  ...      andrew       king       m  24/11/1994   \n",
      "16801  ...       wayne     snipes       m  18/07/1965   \n",
      "16808  ...         ray    robbian       m  21/04/2002   \n",
      "\n",
      "                                          street_address             suburb  \\\n",
      "6                        342  elizabeth  street  flr  6       surry  hills    \n",
      "19                  490  mount  mee  road  dalaneys  ck           d'aguilar   \n",
      "27                          30  dowzer  street  trejago               tully   \n",
      "47                    81  kogarah  lane  argyle  square                reid   \n",
      "55                 234  galloway  street  parry  street            armidale   \n",
      "...                                                  ...                ...   \n",
      "16764    18  kalkaringi  street  kalkarindji  community    victoria  river    \n",
      "16766                  5  brody  street  islands  court       port  kembla    \n",
      "16794   12  napier  close  lidia  perin  medical  cen...             deakin   \n",
      "16801                   5  carrabie  street  raaf  base              darwin   \n",
      "16808                       4  riversdale  road  flt  2            hawthorn   \n",
      "\n",
      "      postcode  state             phone                    email  \n",
      "6       2010.0    nsw   02  2638  0764    ofgmgcaoqj.hotmail.com  \n",
      "19      4514.0    qld   07  4943  7251      gtcnoncbqr.yahoo.com  \n",
      "27      4854.0    qld   07  8094  8977      ihaijdejck.yahoo.com  \n",
      "47      2612.0    act   02  9783  7339   ang.to'chen.hotmail.com  \n",
      "55      5071.0    nsw   08  6891  5098       mfsckakihe.mail.com  \n",
      "...        ...    ...               ...                      ...  \n",
      "16764    800.0     nt   08  9136  5584                            \n",
      "16766   2505.0    nsw   02  4337  2153    yarbro.karen.gmail.com  \n",
      "16794   2600.0    act   02  1375  8070     august100.mail.com.au  \n",
      "16801    800.0     nt   08  3535  6193        snipes97.yahoo.com  \n",
      "16808   3122.0    vic   02  2887  3248         robbian91.aol.com  \n",
      "\n",
      "[2296 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_data = pd.read_csv('files/finalMergeEmail.csv')\n",
    "# new_data['email'] = new_data['email'].fillna('').astype(str)\n",
    "# Define a regex pattern for a valid email address\n",
    "email_pattern = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
    "\n",
    "# Check if each email matches the valid pattern\n",
    "invalid_emails = new_data[~new_data['email'].str.match(email_pattern)]\n",
    "\n",
    "# Display rows with invalid email addresses\n",
    "print(invalid_emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge 2 dataset but only keep the correct email and ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two newly uploaded files\n",
    "file_path_education = 'data_wrangling_education_2024_u7568823.csv'\n",
    "file_path_medical = 'data_wrangling_medical_2024_u7568823.csv'\n",
    "\n",
    "# Load both datasets\n",
    "education_data = pd.read_csv(file_path_education)\n",
    "medical_data = pd.read_csv(file_path_medical)\n",
    "\n",
    "# Merge the datasets based on 'ssn' and keep only the 'email' column\n",
    "merged_data = pd.merge(education_data[['ssn', 'email']], medical_data[['ssn', 'email']], on='ssn', suffixes=('_edu', '_med'))\n",
    "\n",
    "# Apply the function to select the correct email format between the two\n",
    "def choose_correct_email(row):\n",
    "    email_pattern = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
    "    \n",
    "    # Check if the education email is valid\n",
    "    if pd.notnull(row['email_edu']) and re.match(email_pattern, row['email_edu']):\n",
    "        return row['email_edu']\n",
    "    \n",
    "    # Otherwise, check if the medical email is valid\n",
    "    if pd.notnull(row['email_med']) and re.match(email_pattern, row['email_med']):\n",
    "        return row['email_med']\n",
    "    \n",
    "    # If both are invalid or missing, return NaN\n",
    "    return None\n",
    "\n",
    "# Apply the function to the merged data\n",
    "merged_data['correct_email'] = merged_data.apply(choose_correct_email, axis=1)\n",
    "\n",
    "# Drop the individual email columns and keep only the 'ssn' and 'correct_email'\n",
    "final_data = merged_data[['ssn', 'correct_email']]\n",
    "final_data.to_csv('files/correctEmail.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_2780\\3855944602.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  updated_final_data['email'].fillna('missing_email@example.com', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the new uploaded files\n",
    "file_path_correct_email = 'files/correctEmail.csv'\n",
    "file_path_final_imputate_salary = 'files/finalImputateSalary.csv'\n",
    "\n",
    "\n",
    "# Load both datasets\n",
    "correct_email_data = pd.read_csv(file_path_correct_email)\n",
    "final_imputate_salary_data = pd.read_csv(file_path_final_imputate_salary)\n",
    "\n",
    "# Merge the datasets on 'ssn', replacing the 'email' in finalImputateSalary with the correct one from correctEmail.csv\n",
    "updated_final_data = pd.merge(final_imputate_salary_data.drop(columns=['email'], errors='ignore'), \n",
    "                              correct_email_data[['ssn', 'correct_email']], \n",
    "                              on='ssn', \n",
    "                              how='left')\n",
    "\n",
    "# Rename 'correct_email' to 'email' for consistency\n",
    "updated_final_data.rename(columns={'correct_email': 'email'}, inplace=True)\n",
    "updated_final_data['email'].fillna('missing_email@example.com', inplace=True)\n",
    "updated_final_data.to_csv('files/finalMergeEmail.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
