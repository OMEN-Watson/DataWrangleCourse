{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=1237568\n",
    "s2=1238823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique SSNs common in both datasets: 16005\n",
      "Number of SSNs unique to the medical dataset: 3995\n",
      "Number of SSNs unique to the employment dataset: 3185\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for the two datasets (replace these with actual datasets)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Perform an inner join on the 'ssn' attribute to get common SSNs\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner')\n",
    "# tempRes= merged_data['ssn'].count()\n",
    "# Get the number of unique SSNs in both datasets\n",
    "common_ssns_count = merged_data['ssn'].nunique()\n",
    "\n",
    "# SSNs unique to the medical dataset\n",
    "unique_medical_ssns = medical_data[~medical_data['ssn'].isin(employment_data['ssn'])]['ssn'].nunique()\n",
    "\n",
    "# SSNs unique to the employment dataset\n",
    "unique_employment_ssns = employment_data[~employment_data['ssn'].isin(medical_data['ssn'])]['ssn'].nunique()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of unique SSNs common in both datasets: {common_ssns_count}\")\n",
    "print(f\"Number of SSNs unique to the medical dataset: {unique_medical_ssns}\")\n",
    "print(f\"Number of SSNs unique to the employment dataset: {unique_employment_ssns}\")\n",
    "\n",
    "# Save the merged dataset as a new CSV\n",
    "merged_data.to_csv('merged_dataset1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique SSNs with duplicate records in the medical dataset: 0\n",
      "Number of unique SSNs with duplicate records in the employment dataset: 810\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are already in CSV files)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Find duplicate records based on 'ssn' in both datasets\n",
    "medical_duplicates = medical_data[medical_data.duplicated(subset=['ssn'], keep=False)]\n",
    "employment_duplicates = employment_data[employment_data.duplicated(subset=['ssn'], keep=False)]\n",
    "\n",
    "# Count the number of duplicate records in each dataset\n",
    "medical_duplicate_count = medical_duplicates['ssn'].nunique()\n",
    "employment_duplicate_count = employment_duplicates['ssn'].nunique()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of unique SSNs with duplicate records in the medical dataset: {medical_duplicate_count}\")\n",
    "print(f\"Number of unique SSNs with duplicate records in the employment dataset: {employment_duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencies per attribute:\n",
      "first_name: 0\n",
      "middle_name: 3110\n",
      "last_name: 88\n",
      "birth_date: 13221\n",
      "gender: 1631\n",
      "street_address: 6952\n",
      "suburb: 6851\n",
      "postcode: 8649\n",
      "state: 3199\n",
      "phone: 9490\n",
      "email: 7434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "\n",
    "# Merge the datasets on the 'ssn' column using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Define the attributes to compare for inconsistencies (those present in both datasets)\n",
    "attributes_to_compare = ['first_name', 'middle_name', 'last_name', 'birth_date', 'gender', 'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
    "\n",
    "# Initialize a dictionary to track inconsistencies for each attribute\n",
    "inconsistencies = {attribute: 0 for attribute in attributes_to_compare}\n",
    "\n",
    "# Loop through the attributes and count inconsistencies\n",
    "for attribute in attributes_to_compare:\n",
    "    # Compare the medical and employment columns for each attribute\n",
    "    inconsistent_rows = merged_data[merged_data[f'{attribute}_medical'] != merged_data[f'{attribute}_employment']]\n",
    "    \n",
    "    # Count the number of SSNs with inconsistencies for this attribute\n",
    "    inconsistencies[attribute] = inconsistent_rows['ssn'].nunique()\n",
    "\n",
    "# Output the number of inconsistencies for each attribute\n",
    "print(\"Inconsistencies per attribute:\")\n",
    "for attribute, count in inconsistencies.items():\n",
    "    print(f\"{attribute}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.4 comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencies per attribute:\n",
      "first_name: 0\n",
      "middle_name: 3110\n",
      "last_name: 88\n",
      "birth_date: 13221\n",
      "gender: 1631\n",
      "street_address: 6952\n",
      "suburb: 6851\n",
      "postcode: 8649\n",
      "state: 3199\n",
      "phone: 9490\n",
      "email: 7434\n",
      "Resolved data preview:\n",
      "  first_name_resolved middle_name_resolved last_name_resolved  \\\n",
      "0             matthew             mcfarrin            lovette   \n",
      "1                john                  NaN             stultz   \n",
      "2              carrie                 hall             greene   \n",
      "3               diane                    j            gunther   \n",
      "4              joseph                vance         fitzgerald   \n",
      "\n",
      "  birth_date_resolved gender_resolved               street_address_resolved  \\\n",
      "0           5/12/1943               m    36  zouch  street  edward  street    \n",
      "1            6/9/2004               m           533  north  road  longford    \n",
      "2          17/10/1990               f       258  lyons  street  mater  dei    \n",
      "3          25/11/1986               f     25  ney  road  hillcrest  garden    \n",
      "4           23/3/1966               m   81  invermay  road  invermay  farm    \n",
      "\n",
      "  suburb_resolved  postcode_resolved state_resolved    phone_resolved  \\\n",
      "0           young             2594.0            nsw               NaN   \n",
      "1        mortlake             3272.0            vic   03  6780  7652    \n",
      "2       westcourt             4870.0            qld               NaN   \n",
      "3        capalaba             4157.0            qld   07  7140  8329    \n",
      "4         monbulk             3793.0            vic   03  1260  4677    \n",
      "\n",
      "               email_resolved  \n",
      "0       lovette90@hotmail.com  \n",
      "1          john87@mail.com.au  \n",
      "2      greene.carrie@mail.com  \n",
      "3            diane67@mail.com  \n",
      "4  joseph.fitzgerald@mail.com  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Merge the datasets on the 'ssn' column using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Define the attributes to compare for inconsistencies (those present in both datasets)\n",
    "attributes_to_compare = ['first_name', 'middle_name', 'last_name', 'birth_date', 'gender', 'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
    "\n",
    "# Initialize a dictionary to track inconsistencies for each attribute\n",
    "inconsistencies = {attribute: 0 for attribute in attributes_to_compare}\n",
    "\n",
    "# Loop through the attributes and count inconsistencies\n",
    "for attribute in attributes_to_compare:\n",
    "    # Compare the medical and employment columns for each attribute\n",
    "    inconsistent_rows = merged_data[merged_data[f'{attribute}_medical'] != merged_data[f'{attribute}_employment']]\n",
    "    \n",
    "    # Count the number of SSNs with inconsistencies for this attribute\n",
    "    inconsistencies[attribute] = inconsistent_rows['ssn'].nunique()\n",
    "\n",
    "# Output the number of inconsistencies for each attribute\n",
    "print(\"Inconsistencies per attribute:\")\n",
    "for attribute, count in inconsistencies.items():\n",
    "    print(f\"{attribute}: {count}\")\n",
    "\n",
    "# Now, let's resolve the inconsistencies based on specific strategies\n",
    "\n",
    "def resolve_inconsistencies(row, attribute):\n",
    "    medical_value = row[f'{attribute}_medical']\n",
    "    employment_value = row[f'{attribute}_employment']\n",
    "    \n",
    "    # If they are the same, return either one (no inconsistency)\n",
    "    if medical_value == employment_value:\n",
    "        return medical_value\n",
    "    \n",
    "    # Prioritize recency if possible (use timestamp comparison)\n",
    "    if 'consultation_timestamp' in row and 'employment_timestamp' in row:\n",
    "        if row['consultation_timestamp'] > row['employment_timestamp']:\n",
    "            return medical_value  # More recent medical data\n",
    "        else:\n",
    "            return employment_value  # More recent employment data\n",
    "    \n",
    "    # If recency can't be used, handle the inconsistency based on specific logic:\n",
    "    if attribute in ['first_name', 'middle_name', 'last_name']:\n",
    "        # Example: Normalize capitalization issues\n",
    "        if medical_value.lower() == employment_value.lower():\n",
    "            return medical_value.capitalize()  # Return normalized version\n",
    "        else:\n",
    "            # If names are significantly different, use manual intervention (flag the row for review)\n",
    "            return f\"Manual Review Needed for {medical_value} / {employment_value}\"\n",
    "    \n",
    "    if attribute == 'birth_date':\n",
    "        # Example: Normalize date formats if possible\n",
    "        try:\n",
    "            medical_date = pd.to_datetime(medical_value)\n",
    "            employment_date = pd.to_datetime(employment_value)\n",
    "            if medical_date == employment_date:\n",
    "                return medical_date.strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            pass\n",
    "        return f\"Manual Review Needed for {medical_value} / {employment_value}\"\n",
    "    \n",
    "    # For other attributes (e.g., phone, address), just choose one or flag for review\n",
    "    return f\"Manual Review Needed for {medical_value} / {employment_value}\"\n",
    "\n",
    "# Apply the function to resolve inconsistencies for each relevant attribute\n",
    "for attribute in attributes_to_compare:\n",
    "    merged_data[f'{attribute}_resolved'] = merged_data.apply(resolve_inconsistencies, axis=1, args=(attribute,))\n",
    "\n",
    "# Display the resolved data (you can also save it to a file)\n",
    "print(\"Resolved data preview:\")\n",
    "print(merged_data[[f'{attr}_resolved' for attr in attributes_to_compare]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task2.4 comprehensive 2.0, the similarity string (with extra library ) introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Apply the function to resolve inconsistencies for each relevant attribute\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m attributes_to_compare:\n\u001b[1;32m---> 67\u001b[0m     merged_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_resolved\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolve_inconsistencies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Display the resolved data (you can also save it to a file)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolved data preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\PY\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\PY\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PY\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32me:\\PY\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m, in \u001b[0;36mresolve_inconsistencies\u001b[1;34m(row, attribute)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate similarity between the two values for name fields\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiddle_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 31\u001b[0m     similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedical_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memployment_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# If similarity is above the threshold, keep the more recent timestamp value\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m similarity_score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m similarity_threshold:\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mcompute_similarity\u001b[1;34m(str1, str2)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_similarity\u001b[39m(str1, str2):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mratio()\n",
      "File \u001b[1;32me:\\PY\\Lib\\difflib.py:182\u001b[0m, in \u001b[0;36mSequenceMatcher.__init__\u001b[1;34m(self, isjunk, a, b, autojunk)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautojunk \u001b[38;5;241m=\u001b[39m autojunk\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PY\\Lib\\difflib.py:194\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seqs\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the two sequences to be compared.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m>>> s = SequenceMatcher()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m0.75\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_seq1(a)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seq2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PY\\Lib\\difflib.py:248\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seq2\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatching_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopcodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullbcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__chain_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PY\\Lib\\difflib.py:280\u001b[0m, in \u001b[0;36mSequenceMatcher.__chain_b\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2j \u001b[38;5;241m=\u001b[39m b2j \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, elt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    281\u001b[0m     indices \u001b[38;5;241m=\u001b[39m b2j\u001b[38;5;241m.\u001b[39msetdefault(elt, [])\n\u001b[0;32m    282\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Merge the datasets on the 'ssn' column using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Define the attributes to compare for inconsistencies (those present in both datasets)\n",
    "attributes_to_compare = ['first_name', 'middle_name', 'last_name', 'birth_date', 'gender', 'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
    "\n",
    "# Similarity threshold\n",
    "similarity_threshold = 0.8  # You can adjust this threshold based on the similarity required (0.8 = 80%)\n",
    "\n",
    "# Function to compute string similarity using SequenceMatcher\n",
    "def compute_similarity(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "def resolve_inconsistencies(row, attribute):\n",
    "    medical_value = row[f'{attribute}_medical']\n",
    "    employment_value = row[f'{attribute}_employment']\n",
    "    \n",
    "    # If they are exactly the same, return either one (no inconsistency)\n",
    "    if medical_value == employment_value:\n",
    "        return medical_value\n",
    "    \n",
    "    # Calculate similarity between the two values for name fields\n",
    "    if attribute in ['first_name', 'middle_name', 'last_name']:\n",
    "        similarity_score = compute_similarity(medical_value, employment_value)\n",
    "        \n",
    "        # If similarity is above the threshold, keep the more recent timestamp value\n",
    "        if similarity_score >= similarity_threshold:\n",
    "            if row['consultation_timestamp'] > row['employment_timestamp']:\n",
    "                return medical_value  # More recent medical data\n",
    "            else:\n",
    "                return employment_value  # More recent employment data\n",
    "        else:\n",
    "            # If similarity is below the threshold, keep both names\n",
    "            return f\"{medical_value} / {employment_value}\"\n",
    "    \n",
    "    # For other attributes (e.g., birth_date), we can handle recency or flag for manual review\n",
    "    if attribute == 'birth_date':\n",
    "        try:\n",
    "            medical_date = pd.to_datetime(medical_value)\n",
    "            employment_date = pd.to_datetime(employment_value)\n",
    "            if medical_date == employment_date:\n",
    "                return medical_date.strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            pass\n",
    "        return f\"Manual Review Needed for {medical_value} / {employment_value}\"\n",
    "    \n",
    "    # For other attributes like address or phone, prioritize more recent value if timestamps are available\n",
    "    if 'consultation_timestamp' in row and 'employment_timestamp' in row:\n",
    "        if row['consultation_timestamp'] > row['employment_timestamp']:\n",
    "            return medical_value  # More recent medical data\n",
    "        else:\n",
    "            return employment_value  # More recent employment data\n",
    "    \n",
    "    # If no specific rule applies, flag for manual review\n",
    "    return f\"Manual Review Needed for {medical_value} / {employment_value}\"\n",
    "\n",
    "# Apply the function to resolve inconsistencies for each relevant attribute\n",
    " \n",
    "for attribute in attributes_to_compare:\n",
    "    merged_data[f'{attribute}_resolved'] = merged_data.apply(resolve_inconsistencies, axis=1, args=(attribute,))\n",
    "\n",
    "# Display the resolved data (you can also save it to a file)\n",
    "print(\"Resolved data preview:\")\n",
    "print(merged_data[[f'{attr}_resolved' for attr in attributes_to_compare]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. extra different middle name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where SSN is the same but middle name is different:\n",
      "              ssn middle_name_medical middle_name_employment\n",
      "1      e141846696              foster                    NaN\n",
      "4      e145580195                 NaN                  vance\n",
      "10     d165618464                 NaN               pauletta\n",
      "35     i150642589               wayne                    NaN\n",
      "36     g129771524                 NaN                 kappas\n",
      "...           ...                 ...                    ...\n",
      "16792  e169611223                 NaN                  jacob\n",
      "16795  a165306738                 NaN                charles\n",
      "16797  c155601802               marie                    NaN\n",
      "16801  a184970069               wayne                    NaN\n",
      "16804  g191759363                enez                    NaN\n",
      "\n",
      "[3202 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Merge the datasets on the 'ssn' column using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Find rows where the SSN is the same, but the middle name is different\n",
    "different_middle_name = merged_data[merged_data['middle_name_medical'] != merged_data['middle_name_employment']]\n",
    "\n",
    "# Output the filtered rows\n",
    "print(\"Rows where SSN is the same but middle name is different:\")\n",
    "print(different_middle_name[['ssn', 'middle_name_medical', 'middle_name_employment']])\n",
    "\n",
    "# Optional: Save the result to a CSV file\n",
    "different_middle_name[['ssn', 'middle_name_medical', 'middle_name_employment']].to_csv('ssn_diff_middle_name.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. extra different email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with the same SSN but different emails:\n",
      "              ssn           email_medical              email_employment\n",
      "6      i131945217  ofgmgcaoqj.hotmail.com        ofgmgcaoqj@hotmail.com\n",
      "7      c143442126                     NaN          polk.allen@gmail.com\n",
      "8      g154869706                     NaN           transou72@gmail.com\n",
      "14     b159377382  moore.richard@mail.com                           NaN\n",
      "16     i172782745                     NaN       irvine.darrin@gmail.com\n",
      "...           ...                     ...                           ...\n",
      "16801  a184970069      snipes97.yahoo.com            snipes97@yahoo.com\n",
      "16804  g191759363                     NaN  finkelstein.jessica@mail.com\n",
      "16808  d136644076       robbian91.aol.com             robbian91@aol.com\n",
      "16809  h185183775                     NaN               green25@aol.com\n",
      "16813  a124600434     isenkcafgt@mail.com                           NaN\n",
      "\n",
      "[7755 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Merge the datasets on 'ssn' using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Filter rows where ssn is the same but email is different\n",
    "different_email_records = merged_data[merged_data['email_medical'] != merged_data['email_employment']]\n",
    "\n",
    "# Output the records with the same SSN but different emails\n",
    "print(\"Records with the same SSN but different emails:\")\n",
    "print(different_email_records[['ssn', 'email_medical', 'email_employment']])\n",
    "\n",
    "# Optionally, you can save these records to a CSV file\n",
    "different_email_records[['ssn', 'email_medical', 'email_employment']].to_csv('ssn_different_email_records.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. extra different email (both not null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with the same SSN but different emails (and non-null emails):\n",
      "              ssn            email_medical         email_employment\n",
      "6      i131945217   ofgmgcaoqj.hotmail.com   ofgmgcaoqj@hotmail.com\n",
      "19     g197247139     gtcnoncbqr.yahoo.com     gtcnoncbqr@yahoo.com\n",
      "27     d113054410     ihaijdejck.yahoo.com     ihaijdejck@yahoo.com\n",
      "47     c126684873  ang.to'chen.hotmail.com  ang.to'chen@hotmail.com\n",
      "55     f166206248      mfsckakihe.mail.com      mfsckakihe@mail.com\n",
      "...           ...                      ...                      ...\n",
      "16752  h131700505   lunsford67.mail.com.au   lunsford67@mail.com.au\n",
      "16761  f143373531     thompson90.yahoo.com     thompson90@yahoo.com\n",
      "16794  e155951170    august100.mail.com.au    august100@mail.com.au\n",
      "16801  a184970069       snipes97.yahoo.com       snipes97@yahoo.com\n",
      "16808  d136644076        robbian91.aol.com        robbian91@aol.com\n",
      "\n",
      "[1627 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Merge the datasets on 'ssn' using an inner join\n",
    "merged_data = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Filter rows where both emails are not null and are different\n",
    "non_null_email_records = merged_data[\n",
    "    (merged_data['email_medical'].notna()) &  # Medical email is not null\n",
    "    (merged_data['email_employment'].notna()) &  # Employment email is not null\n",
    "    (merged_data['email_medical'] != merged_data['email_employment'])  # Emails are different\n",
    "]\n",
    "\n",
    "# Output the records with the same SSN but different emails\n",
    "print(\"Records with the same SSN but different emails (and non-null emails):\")\n",
    "print(non_null_email_records[['ssn', 'email_medical', 'email_employment']])\n",
    "\n",
    "# Optionally, you can save these records to a CSV file\n",
    "non_null_email_records[['ssn', 'email_medical', 'email_employment']].to_csv('ssn_different_non_null_email_records.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
