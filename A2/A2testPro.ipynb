{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique SSNs occurred in common in both datasets: 16005\n",
      "Number of unique SSNs only in the medical dataset: 3995\n",
      "Number of unique SSNs only in the employment dataset: 3185\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "# Replace 'medical_dataset.csv' and 'employment_dataset.csv' with the actual file names or paths\n",
    "medical_dataset = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_dataset = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Ensure the 'ssn' columns are strings and strip any leading/trailing whitespaces\n",
    "medical_dataset['ssn'] = medical_dataset['ssn'].astype(str).str.strip()\n",
    "employment_dataset['ssn'] = employment_dataset['ssn'].astype(str).str.strip()\n",
    "\n",
    "# Handle missing SSNs by removing rows with null SSN values\n",
    "medical_dataset = medical_dataset.dropna(subset=['ssn'])\n",
    "employment_dataset = employment_dataset.dropna(subset=['ssn'])\n",
    "\n",
    "# Remove duplicate SSNs within each dataset if any\n",
    "medical_dataset = medical_dataset.drop_duplicates(subset=['ssn'])\n",
    "employment_dataset = employment_dataset.drop_duplicates(subset=['ssn'])\n",
    "\n",
    "# Extract unique SSNs from each dataset\n",
    "unique_ssn_medical = set(medical_dataset['ssn'])\n",
    "unique_ssn_employment = set(employment_dataset['ssn'])\n",
    "\n",
    "# Calculate SSNs in common\n",
    "ssn_common = unique_ssn_medical.intersection(unique_ssn_employment)\n",
    "count_common = len(ssn_common)\n",
    "\n",
    "# Calculate SSNs only in the medical dataset\n",
    "ssn_only_medical = unique_ssn_medical.difference(unique_ssn_employment)\n",
    "count_only_medical = len(ssn_only_medical)\n",
    "\n",
    "# Calculate SSNs only in the employment dataset\n",
    "ssn_only_employment = unique_ssn_employment.difference(unique_ssn_medical)\n",
    "count_only_employment = len(ssn_only_employment)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique SSNs occurred in common in both datasets: {count_common}\")\n",
    "print(f\"Number of unique SSNs only in the medical dataset: {count_only_medical}\")\n",
    "print(f\"Number of unique SSNs only in the employment dataset: {count_only_employment}\")\n",
    "\n",
    "# Merge the datasets on 'ssn' to create the combined dataset\n",
    "merged_dataset = pd.merge(medical_dataset, employment_dataset, on='ssn', how='outer', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# Save the merged dataset to a new CSV file\n",
    "merged_dataset.to_csv('merged_dataset2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate SSNs in the medical dataset: 0\n",
      "Number of duplicate SSNs in the employment dataset: 810\n"
     ]
    }
   ],
   "source": [
    "# For Medical Dataset\n",
    "# Sample data for the two datasets (replace these with actual datasets)\n",
    "medical_dataset = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_dataset = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "duplicate_ssns_medical = medical_dataset[medical_dataset.duplicated(subset='ssn', keep=False)]\n",
    "count_duplicates_medical = duplicate_ssns_medical['ssn'].nunique()\n",
    "\n",
    "# For Employment Dataset\n",
    "duplicate_ssns_employment = employment_dataset[employment_dataset.duplicated(subset='ssn', keep=False)]\n",
    "count_duplicates_employment = duplicate_ssns_employment['ssn'].nunique()\n",
    "\n",
    "print(f\"Number of duplicate SSNs in the medical dataset: {count_duplicates_medical}\")\n",
    "print(f\"Number of duplicate SSNs in the employment dataset: {count_duplicates_employment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task2.4 easy mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'merged_dataset' is the DataFrame after merging on 'ssn'\n",
    "# 'merged_dataset' has suffixes '_medical' and '_employment' for overlapping columns\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "\n",
    "# Merge the datasets on the 'ssn' column using an inner join\n",
    "merged_dataset = pd.merge(medical_data, employment_data, on='ssn', how='inner', suffixes=('_medical', '_employment'))\n",
    "\n",
    "# List of attributes to compare\n",
    "attributes_to_compare = ['first_name', 'middle_name', 'last_name', 'gender', 'birth_date',\n",
    "                         'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
    "\n",
    "# Initialize a dictionary to hold counts of inconsistencies\n",
    "inconsistency_counts = {attr: 0 for attr in attributes_to_compare}\n",
    "\n",
    "# Group the merged dataset by 'ssn' to handle multiple records per individual\n",
    "grouped = merged_dataset.groupby('ssn')\n",
    "\n",
    "for ssn, group in grouped:\n",
    "    for attr in attributes_to_compare:\n",
    "        attr_medical = attr + '_medical'\n",
    "        attr_employment = attr + '_employment'\n",
    "        \n",
    "        # Check if both attributes exist\n",
    "        if attr_medical in group.columns and attr_employment in group.columns:\n",
    "            # Flag to determine if attribute is consistent for this ssn\n",
    "            consistent = False\n",
    "            \n",
    "            # Iterate through records for this ssn\n",
    "            for idx, row in group.iterrows():\n",
    "                val_medical = str(row.get(attr_medical, '')).strip().lower()\n",
    "                val_employment = str(row.get(attr_employment, '')).strip().lower()\n",
    "                \n",
    "                # Check for at least one consistent pair\n",
    "                if val_medical == val_employment or not val_medical or not val_employment:\n",
    "                    consistent = True\n",
    "                    break  # No need to check further\n",
    "                \n",
    "            if not consistent:\n",
    "                # Count inconsistency only once per ssn per attribute\n",
    "                inconsistency_counts[attr] += 1\n",
    "\n",
    "# Display the counts of inconsistencies\n",
    "for attr, count in inconsistency_counts.items():\n",
    "    print(f\"Attribute '{attr}' has {count} inconsistencies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.4 comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_6988\\54499970.py:56: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ssn  age_at_consultation      medicare_number marital_status  \\\n",
      "0  a100013007                 23.0   8553  21580  1  2     not-married   \n",
      "1  a100113242                  NaN                  NaN            NaN   \n",
      "2  a100146498                 24.0   5170  65912  1  3         married   \n",
      "3  a100176744                  NaN                  NaN            NaN   \n",
      "4  a100186005                 26.0   5906  91908  2  2     not-married   \n",
      "\n",
      "   height  weight   bmi  blood_pressure  cholesterol_level  smoking_status  \\\n",
      "0   178.0   -99.0  29.0            78.0              170.0             0.0   \n",
      "1     NaN     NaN   NaN             NaN                NaN             NaN   \n",
      "2   180.0   133.0  41.0            67.0              184.0             1.0   \n",
      "3     NaN     NaN   NaN             NaN                NaN             NaN   \n",
      "4   169.0   120.0  42.0            81.0              166.0             0.0   \n",
      "\n",
      "   ... last_name gender  birth_date  \\\n",
      "0  ...  hercules      F  1989-08-06   \n",
      "1  ...     eller      f   26/1/1992   \n",
      "2  ...     smith      F  1990-12-31   \n",
      "3  ...    thorpe      f   23/5/1946   \n",
      "4  ...      webb      F  1986-10-29   \n",
      "\n",
      "                                    street_address                 suburb  \\\n",
      "0                    113  the  grange  the  grove           tweed  heads    \n",
      "1                              5  Martens  Street    Mount  Warren  Park    \n",
      "2   258  spring  street  yukana  retirement  vlge               toowoomba   \n",
      "3                                38  Cintra  Road           Bowen  Hills    \n",
      "4                       2  jersey  street  flt  2                  balwyn   \n",
      "\n",
      "   postcode state             phone                   email     rec_id  \n",
      "0    2485.0   nsw   02  8550  7613   qqngtbilnt@mail.com.au  R70001030  \n",
      "1    4207.0   QLD   07  0349  7190    latessa24@mail.com.au  R01120432  \n",
      "2    4350.0   qld   07  4435  9613    ellen.smith@gmail.com  R40681094  \n",
      "3    4006.0   QLD               NaN      thorpe98@gmail.com  R04677014  \n",
      "4    3103.0   vic   03  1115  3346    webb.ruth@hotmail.com  R05016080  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load the datasets\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Ensure the 'ssn' columns are strings and strip any leading/trailing whitespaces\n",
    "medical_dataset['ssn'] = medical_dataset['ssn'].astype(str).str.strip()\n",
    "employment_dataset['ssn'] = employment_dataset['ssn'].astype(str).str.strip()\n",
    "\n",
    "# Handle missing SSNs by removing rows with null SSN values\n",
    "medical_dataset = medical_dataset.dropna(subset=['ssn'])\n",
    "employment_dataset = employment_dataset.dropna(subset=['ssn'])\n",
    "\n",
    "# Merge the datasets on 'ssn' using outer join to include all records\n",
    "merged_dataset = pd.merge(\n",
    "    medical_dataset, employment_dataset, on='ssn', how='outer', suffixes=('_medical', '_employment')\n",
    ")\n",
    "\n",
    "# List of attributes to resolve inconsistencies for\n",
    "attributes_to_resolve = [\n",
    "    'first_name', 'middle_name', 'last_name', 'gender', 'birth_date',\n",
    "    'street_address', 'suburb', 'postcode', 'state', 'phone', 'email'\n",
    "]\n",
    "\n",
    "# Function to standardize text attributes\n",
    "def standardize_text(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    return str(value).strip().lower()\n",
    "\n",
    "# Function to compare similarity between two strings\n",
    "def is_similar(a, b, threshold=0.8):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# Custom function to parse dates with potential '24:' hour issue\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_date_with_24_hour(date_str):\n",
    "    if pd.isnull(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        # Handle the '24:' hour by replacing it with '00:' and adding one day\n",
    "        if '24:' in date_str:\n",
    "            # Replace '24:' with '00:'\n",
    "            corrected_date_str = date_str.replace('24:', '00:')\n",
    "            # Parse the date\n",
    "            parsed_date = pd.to_datetime(corrected_date_str, utc=True)\n",
    "            # Add one day\n",
    "            parsed_date += timedelta(days=1)\n",
    "            return parsed_date\n",
    "        else:\n",
    "            # Parse normally\n",
    "            return pd.to_datetime(date_str, utc=True)\n",
    "    except Exception as e:\n",
    "        # If parsing fails, return NaT\n",
    "        return pd.NaT\n",
    "\n",
    "# Function to resolve inconsistencies for a single attribute\n",
    "def resolve_attribute(row, attr):\n",
    "    attr_medical = attr + '_medical'\n",
    "    attr_employment = attr + '_employment'\n",
    "    val_medical = row.get(attr_medical, np.nan)\n",
    "    val_employment = row.get(attr_employment, np.nan)\n",
    "    \n",
    "    # Standardize values\n",
    "    val_medical_std = standardize_text(val_medical)\n",
    "    val_employment_std = standardize_text(val_employment)\n",
    "    \n",
    "    # If both values are missing, return NaN\n",
    "    if not val_medical_std and not val_employment_std:\n",
    "        return np.nan\n",
    "    \n",
    "    # If one value is missing, use the other\n",
    "    if not val_medical_std:\n",
    "        return val_employment\n",
    "    if not val_employment_std:\n",
    "        return val_medical\n",
    "    \n",
    "    # Resolve based on attribute type\n",
    "    if attr in ['first_name', 'middle_name', 'last_name']:\n",
    "        # Check for typos or common variations\n",
    "        if val_medical_std == val_employment_std or is_similar(val_medical_std, val_employment_std):\n",
    "            # Use the more complete or formal version if possible\n",
    "            return val_medical if len(val_medical_std) >= len(val_employment_std) else val_employment\n",
    "        else:\n",
    "            # Keep both names if they are different (e.g., nickname vs. formal name)\n",
    "            return f\"{val_medical} / {val_employment}\"\n",
    "    elif attr == 'gender':\n",
    "        # Standardize gender codes\n",
    "        gender_mapping = {'male': 'M', 'm': 'M', 'female': 'F', 'f': 'F'}\n",
    "        val_medical_std = gender_mapping.get(val_medical_std, val_medical_std.upper())\n",
    "        val_employment_std = gender_mapping.get(val_employment_std, val_employment_std.upper())\n",
    "        if val_medical_std == val_employment_std:\n",
    "            return val_medical_std\n",
    "        else:\n",
    "            # Mark as 'Unknown' if inconsistency remains\n",
    "            return 'Unknown'\n",
    "    elif attr == 'birth_date':\n",
    "        # Use custom date parser\n",
    "        date_medical = parse_date_with_24_hour(val_medical)\n",
    "        date_employment = parse_date_with_24_hour(val_employment)\n",
    "        if pd.notnull(date_medical) and pd.notnull(date_employment):\n",
    "            if date_medical == date_employment:\n",
    "                return date_medical.date()\n",
    "            else:\n",
    "                # Cross-check with age attributes if available\n",
    "                age_medical = row.get('age_at_consultation', np.nan)\n",
    "                age_employment = row.get('current_age', np.nan)\n",
    "                today = pd.Timestamp.today()\n",
    "                if not pd.isnull(age_medical) and not pd.isnull(age_employment):\n",
    "                    # Calculate expected birth dates\n",
    "                    expected_birth_medical = today - pd.Timedelta(days=age_medical * 365)\n",
    "                    expected_birth_employment = today - pd.Timedelta(days=age_employment * 365)\n",
    "                    diff_medical = abs((date_medical - expected_birth_medical).days)\n",
    "                    diff_employment = abs((date_employment - expected_birth_employment).days)\n",
    "                    return date_medical.date() if diff_medical <= diff_employment else date_employment.date()\n",
    "                else:\n",
    "                    # Use the date that is more plausible\n",
    "                    return date_medical.date() if date_medical.year > 1900 else date_employment.date()\n",
    "        elif pd.notnull(date_medical):\n",
    "            return date_medical.date()\n",
    "        elif pd.notnull(date_employment):\n",
    "            return date_employment.date()\n",
    "        else:\n",
    "            return np.nan\n",
    "    elif attr in ['street_address', 'suburb', 'postcode', 'state']:\n",
    "        # Use the most recent address based on event dates\n",
    "        date_medical_str = row.get('consultation_timestamp', np.nan)\n",
    "        date_employment_str = row.get('employment_timestamp', np.nan)\n",
    "        date_medical = parse_date_with_24_hour(date_medical_str)\n",
    "        date_employment = parse_date_with_24_hour(date_employment_str)\n",
    "        if pd.notnull(date_medical) and pd.notnull(date_employment):\n",
    "            if date_medical >= date_employment:\n",
    "                return val_medical\n",
    "            else:\n",
    "                return val_employment\n",
    "        elif pd.notnull(date_medical):\n",
    "            return val_medical\n",
    "        elif pd.notnull(date_employment):\n",
    "            return val_employment\n",
    "        else:\n",
    "            # If dates are not available, use the non-null value\n",
    "            return val_medical if val_medical_std else val_employment\n",
    "    elif attr in ['phone', 'email']:\n",
    "        # Combine contact methods into a list, removing duplicates\n",
    "        contacts = set()\n",
    "        if val_medical_std:\n",
    "            contacts.add(val_medical)\n",
    "        if val_employment_std:\n",
    "            contacts.add(val_employment)\n",
    "        # Return combined contacts separated by semicolon\n",
    "        return '; '.join(contacts)\n",
    "    else:\n",
    "        # For other attributes, prefer non-null over null\n",
    "        return val_medical if val_medical_std else val_employment\n",
    "\n",
    "# Apply the resolution function to each attribute\n",
    "for attr in attributes_to_resolve:\n",
    "    merged_dataset[attr] = merged_dataset.apply(lambda row: resolve_attribute(row, attr), axis=1)\n",
    "    \n",
    "    # Drop the individual columns from medical and employment datasets\n",
    "    attr_medical = attr + '_medical'\n",
    "    attr_employment = attr + '_employment'\n",
    "    if attr_medical in merged_dataset.columns:\n",
    "        merged_dataset.drop(columns=[attr_medical], inplace=True)\n",
    "    if attr_employment in merged_dataset.columns:\n",
    "        merged_dataset.drop(columns=[attr_employment], inplace=True)\n",
    "\n",
    "# Handle additional attributes unique to each dataset\n",
    "# Keep other attributes from medical dataset\n",
    "medical_attrs = [col for col in medical_dataset.columns if col not in ['ssn'] + attributes_to_resolve]\n",
    "# Keep other attributes from employment dataset\n",
    "employment_attrs = [col for col in employment_dataset.columns if col not in ['ssn'] + attributes_to_resolve]\n",
    "\n",
    "# For attributes unique to each dataset, ensure they are included in the merged dataset\n",
    "for attr in medical_attrs:\n",
    "    attr_medical = attr + '_medical'\n",
    "    if attr_medical in merged_dataset.columns:\n",
    "        merged_dataset[attr] = merged_dataset[attr_medical]\n",
    "        merged_dataset.drop(columns=[attr_medical], inplace=True)\n",
    "    elif attr in merged_dataset.columns:\n",
    "        continue\n",
    "    else:\n",
    "        merged_dataset[attr] = np.nan\n",
    "\n",
    "for attr in employment_attrs:\n",
    "    attr_employment = attr + '_employment'\n",
    "    if attr_employment in merged_dataset.columns:\n",
    "        merged_dataset[attr] = merged_dataset[attr_employment]\n",
    "        merged_dataset.drop(columns=[attr_employment], inplace=True)\n",
    "    elif attr in merged_dataset.columns:\n",
    "        continue\n",
    "    else:\n",
    "        merged_dataset[attr] = np.nan\n",
    "\n",
    "# Now, merged_dataset contains resolved attributes and all other attributes\n",
    "# You can save the cleaned and merged dataset to a new CSV file\n",
    "merged_dataset.to_csv('merged_dataset_cleaned.csv', index=False)\n",
    "\n",
    "# Optionally, display a sample of the cleaned dataset\n",
    "print(merged_dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.4 comprehensive 2, with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_6988\\1768183520.py:46: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, utc=True)\n",
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_6988\\1768183520.py:46: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, utc=True)\n",
      "C:\\Users\\13521\\AppData\\Local\\Temp\\ipykernel_6988\\1768183520.py:46: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistency counts per attribute:\n",
      "- first_name: 0 inconsistencies\n",
      "- middle_name: 2801 inconsistencies\n",
      "- last_name: 0 inconsistencies\n",
      "- gender: 1631 inconsistencies\n",
      "- birth_date: 0 inconsistencies\n",
      "- street_address: 6597 inconsistencies\n",
      "- suburb: 6490 inconsistencies\n",
      "- postcode: 8358 inconsistencies\n",
      "- state: 2677 inconsistencies\n",
      "- phone: 8565 inconsistencies\n",
      "- email: 6878 inconsistencies\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the datasets (assuming they are in CSV format)\n",
    "medical_data = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_data = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Ensure the 'ssn' columns are strings and strip any leading/trailing whitespaces\n",
    "medical_dataset['ssn'] = medical_dataset['ssn'].astype(str).str.strip()\n",
    "employment_dataset['ssn'] = employment_dataset['ssn'].astype(str).str.strip()\n",
    "\n",
    "# Handle missing SSNs by removing rows with null SSN values\n",
    "medical_dataset = medical_dataset.dropna(subset=['ssn'])\n",
    "employment_dataset = employment_dataset.dropna(subset=['ssn'])\n",
    "\n",
    "# Merge the datasets on 'ssn' using outer join to include all records\n",
    "merged_dataset = pd.merge(\n",
    "    medical_dataset, employment_dataset, on='ssn', how='outer', suffixes=('_medical', '_employment')\n",
    ")\n",
    "\n",
    "# List of attributes to compare\n",
    "attributes_to_compare = [\n",
    "    'first_name', 'middle_name', 'last_name', 'gender', 'birth_date',\n",
    "    'street_address', 'suburb', 'postcode', 'state', 'phone', 'email'\n",
    "]\n",
    "\n",
    "# Function to standardize text attributes\n",
    "def standardize_text(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    return str(value).strip().lower()\n",
    "\n",
    "# Custom function to parse dates with potential '24:' hour issue\n",
    "def parse_date_with_24_hour(date_str):\n",
    "    if pd.isnull(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        if '24:' in date_str:\n",
    "            corrected_date_str = date_str.replace('24:', '00:')\n",
    "            parsed_date = pd.to_datetime(corrected_date_str, utc=True)\n",
    "            parsed_date += timedelta(days=1)\n",
    "            return parsed_date\n",
    "        else:\n",
    "            return pd.to_datetime(date_str, utc=True)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "# Function to compare two values for consistency\n",
    "def compare_values(val_medical, val_employment, attr):\n",
    "    val_medical_std = standardize_text(val_medical)\n",
    "    val_employment_std = standardize_text(val_employment)\n",
    "\n",
    "    # If both values are missing, consider them consistent\n",
    "    if not val_medical_std and not val_employment_std:\n",
    "        return True\n",
    "\n",
    "    # If one value is missing, consider them inconsistent\n",
    "    if not val_medical_std or not val_employment_std:\n",
    "        return False\n",
    "\n",
    "    if attr in ['first_name', 'middle_name', 'last_name']:\n",
    "        # Use similarity threshold to account for typos\n",
    "        similarity_ratio = SequenceMatcher(None, val_medical_std, val_employment_std).ratio()\n",
    "        return similarity_ratio >= 0.8\n",
    "    elif attr == 'gender':\n",
    "        gender_mapping = {'male': 'M', 'm': 'M', 'female': 'F', 'f': 'F'}\n",
    "        val_medical_std = gender_mapping.get(val_medical_std, val_medical_std.upper())\n",
    "        val_employment_std = gender_mapping.get(val_employment_std, val_employment_std.upper())\n",
    "        return val_medical_std == val_employment_std\n",
    "    elif attr == 'birth_date':\n",
    "        date_medical = parse_date_with_24_hour(val_medical)\n",
    "        date_employment = parse_date_with_24_hour(val_employment)\n",
    "        if pd.isnull(date_medical) and pd.isnull(date_employment):\n",
    "            return True\n",
    "        return date_medical == date_employment\n",
    "    else:\n",
    "        # For other attributes, check exact match\n",
    "        return val_medical_std == val_employment_std\n",
    "\n",
    "# Initialize a dictionary to hold counts of inconsistencies\n",
    "inconsistency_counts = {attr: 0 for attr in attributes_to_compare}\n",
    "\n",
    "# Get the list of SSNs common to both datasets\n",
    "common_ssns = set(medical_dataset['ssn']).intersection(set(employment_dataset['ssn']))\n",
    "\n",
    "# For each SSN, check for inconsistencies\n",
    "for ssn in common_ssns:\n",
    "    # Get all records for this SSN in both datasets\n",
    "    records_medical = medical_dataset[medical_dataset['ssn'] == ssn]\n",
    "    records_employment = employment_dataset[employment_dataset['ssn'] == ssn]\n",
    "\n",
    "    for attr in attributes_to_compare:\n",
    "        attr_medical = attr\n",
    "        attr_employment = attr\n",
    "\n",
    "        # Flag to determine if attribute is consistent for this SSN\n",
    "        consistent = False\n",
    "\n",
    "        # Check all combinations of records for this SSN\n",
    "        for idx_medical, row_medical in records_medical.iterrows():\n",
    "            val_medical = row_medical.get(attr_medical, np.nan)\n",
    "            for idx_employment, row_employment in records_employment.iterrows():\n",
    "                val_employment = row_employment.get(attr_employment, np.nan)\n",
    "\n",
    "                # Compare the values\n",
    "                if compare_values(val_medical, val_employment, attr):\n",
    "                    consistent = True\n",
    "                    break  # No need to check further\n",
    "            if consistent:\n",
    "                break  # No need to check further\n",
    "\n",
    "        if not consistent:\n",
    "            # Count inconsistency only once per SSN per attribute\n",
    "            inconsistency_counts[attr] += 1\n",
    "\n",
    "# Print the counts of inconsistencies\n",
    "print(\"Inconsistency counts per attribute:\")\n",
    "for attr, count in inconsistency_counts.items():\n",
    "    print(f\"- {attr}: {count} inconsistencies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task2.4 integrate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the datasets\n",
    "medical_dataset = pd.read_csv('data_wrangling_medical_2024_u7568823.csv')\n",
    "employment_dataset = pd.read_csv('data_wrangling_education_2024_u7568823.csv')\n",
    "\n",
    "# Ensure the 'ssn' columns are strings and strip any leading/trailing whitespaces\n",
    "medical_dataset['ssn'] = medical_dataset['ssn'].astype(str).str.strip()\n",
    "employment_dataset['ssn'] = employment_dataset['ssn'].astype(str).str.strip()\n",
    "\n",
    "# Handle missing SSNs by removing rows with null SSN values\n",
    "medical_dataset = medical_dataset.dropna(subset=['ssn'])\n",
    "employment_dataset = employment_dataset.dropna(subset=['ssn'])\n",
    "\n",
    "# Merge the datasets on 'ssn' using outer join to include all records\n",
    "merged_dataset = pd.merge(\n",
    "    medical_dataset, employment_dataset, on='ssn', how='outer', suffixes=('_medical', '_employment')\n",
    ")\n",
    "\n",
    "# List of attributes to resolve inconsistencies for\n",
    "attributes_to_resolve = [\n",
    "    'first_name', 'middle_name', 'last_name', 'gender', 'birth_date',\n",
    "    'street_address', 'suburb', 'postcode', 'state', 'phone', 'email'\n",
    "]\n",
    "\n",
    "# Function to standardize text attributes\n",
    "def standardize_text(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    return str(value).strip().lower()\n",
    "\n",
    "# Function to compare similarity between two strings\n",
    "def is_similar(a, b, threshold=0.8):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# Custom function to parse dates with potential '24:' hour issue\n",
    "def parse_date_with_24_hour(date_str):\n",
    "    if pd.isnull(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        # Handle the '24:' hour by replacing it with '00:' and adding one day\n",
    "        if '24:' in date_str:\n",
    "            # Replace '24:' with '00:'\n",
    "            corrected_date_str = date_str.replace('24:', '00:')\n",
    "            # Parse the date\n",
    "            parsed_date = pd.to_datetime(corrected_date_str, utc=True)\n",
    "            # Add one day\n",
    "            parsed_date += timedelta(days=1)\n",
    "            return parsed_date\n",
    "        else:\n",
    "            # Parse normally\n",
    "            return pd.to_datetime(date_str, utc=True)\n",
    "    except Exception as e:\n",
    "        # If parsing fails, return NaT\n",
    "        return pd.NaT\n",
    "\n",
    "# Initialize a dictionary to hold counts of inconsistencies\n",
    "inconsistency_counts = {attr: 0 for attr in attributes_to_resolve}\n",
    "\n",
    "# Get the list of common SSNs\n",
    "ssn_medical = set(medical_dataset['ssn'])\n",
    "ssn_employment = set(employment_dataset['ssn'])\n",
    "ssn_common = ssn_medical.intersection(ssn_employment)\n",
    "\n",
    "# Filter the merged dataset to only include records with SSNs common to both datasets\n",
    "merged_common_ssn = merged_dataset[merged_dataset['ssn'].isin(ssn_common)]\n",
    "\n",
    "# Group by SSN\n",
    "grouped = merged_common_ssn.groupby('ssn')\n",
    "\n",
    "for ssn, group in grouped:\n",
    "    # For each attribute\n",
    "    for attr in attributes_to_resolve:\n",
    "        attr_medical = attr + '_medical'\n",
    "        attr_employment = attr + '_employment'\n",
    "\n",
    "        # Get unique values for this attribute from medical and employment datasets\n",
    "        vals_medical = group[attr_medical].dropna().apply(standardize_text).unique() if attr_medical in group.columns else []\n",
    "        vals_employment = group[attr_employment].dropna().apply(standardize_text).unique() if attr_employment in group.columns else []\n",
    "\n",
    "        # If both datasets have values for this attribute for this SSN\n",
    "        if len(vals_medical) > 0 and len(vals_employment) > 0:\n",
    "            # Check if there is at least one common value\n",
    "            match_found = False\n",
    "            for val_med in vals_medical:\n",
    "                for val_emp in vals_employment:\n",
    "                    # For attributes like birth_date, we may need special handling\n",
    "                    if attr == 'birth_date':\n",
    "                        # Parse dates\n",
    "                        date_med = parse_date_with_24_hour(val_med)\n",
    "                        date_emp = parse_date_with_24_hour(val_emp)\n",
    "                        if pd.notnull(date_med) and pd.notnull(date_emp):\n",
    "                            if date_med.date() == date_emp.date():\n",
    "                                match_found = True\n",
    "                                break\n",
    "                    else:\n",
    "                        if val_med == val_emp:\n",
    "                            match_found = True\n",
    "                            break\n",
    "                if match_found:\n",
    "                    break\n",
    "            if not match_found:\n",
    "                # No matching values found, increment inconsistency count\n",
    "                inconsistency_counts[attr] += 1\n",
    "        else:\n",
    "            # If either dataset does not have values for this attribute for this SSN, consider it consistent\n",
    "            pass\n",
    "\n",
    "# Print the counts of inconsistencies\n",
    "print(\"Inconsistencies Found Per Attribute:\")\n",
    "for attr, count in inconsistency_counts.items():\n",
    "    print(f\"Attribute '{attr}' has {count} inconsistencies.\")\n",
    "\n",
    "# Function to resolve inconsistencies for a single attribute\n",
    "def resolve_attribute(row, attr):\n",
    "    attr_medical = attr + '_medical'\n",
    "    attr_employment = attr + '_employment'\n",
    "    val_medical = row.get(attr_medical, np.nan)\n",
    "    val_employment = row.get(attr_employment, np.nan)\n",
    "    \n",
    "    # Standardize values\n",
    "    val_medical_std = standardize_text(val_medical)\n",
    "    val_employment_std = standardize_text(val_employment)\n",
    "    \n",
    "    # If both values are missing, return NaN\n",
    "    if not val_medical_std and not val_employment_std:\n",
    "        return np.nan\n",
    "    \n",
    "    # If one value is missing, use the other\n",
    "    if not val_medical_std:\n",
    "        return val_employment\n",
    "    if not val_employment_std:\n",
    "        return val_medical\n",
    "    \n",
    "    # Resolve based on attribute type\n",
    "    if attr in ['first_name', 'middle_name', 'last_name']:\n",
    "        # Check for typos or common variations\n",
    "        if val_medical_std == val_employment_std or is_similar(val_medical_std, val_employment_std):\n",
    "            # Use the more complete or formal version if possible\n",
    "            return val_medical if len(val_medical_std) >= len(val_employment_std) else val_employment\n",
    "        else:\n",
    "            # Keep both names if they are different (e.g., nickname vs. formal name)\n",
    "            return f\"{val_medical} / {val_employment}\"\n",
    "    elif attr == 'gender':\n",
    "        # Standardize gender codes\n",
    "        gender_mapping = {'male': 'M', 'm': 'M', 'female': 'F', 'f': 'F'}\n",
    "        val_medical_std = gender_mapping.get(val_medical_std, val_medical_std.upper())\n",
    "        val_employment_std = gender_mapping.get(val_employment_std, val_employment_std.upper())\n",
    "        if val_medical_std == val_employment_std:\n",
    "            return val_medical_std\n",
    "        else:\n",
    "            # Mark as 'Unknown' if inconsistency remains\n",
    "            return 'Unknown'\n",
    "    elif attr == 'birth_date':\n",
    "        # Use custom date parser\n",
    "        date_medical = parse_date_with_24_hour(val_medical)\n",
    "        date_employment = parse_date_with_24_hour(val_employment)\n",
    "        if pd.notnull(date_medical) and pd.notnull(date_employment):\n",
    "            if date_medical.date() == date_employment.date():\n",
    "                return date_medical.date()\n",
    "            else:\n",
    "                # Cross-check with age attributes if available\n",
    "                age_medical = row.get('age_at_consultation', np.nan)\n",
    "                age_employment = row.get('current_age', np.nan)\n",
    "                today = pd.Timestamp.today()\n",
    "                if not pd.isnull(age_medical) and not pd.isnull(age_employment):\n",
    "                    # Calculate expected birth dates\n",
    "                    expected_birth_medical = today - pd.Timedelta(days=age_medical * 365)\n",
    "                    expected_birth_employment = today - pd.Timedelta(days=age_employment * 365)\n",
    "                    diff_medical = abs((date_medical - expected_birth_medical).days)\n",
    "                    diff_employment = abs((date_employment - expected_birth_employment).days)\n",
    "                    return date_medical.date() if diff_medical <= diff_employment else date_employment.date()\n",
    "                else:\n",
    "                    # Use the date that is more plausible\n",
    "                    return date_medical.date() if date_medical.year > 1900 else date_employment.date()\n",
    "        elif pd.notnull(date_medical):\n",
    "            return date_medical.date()\n",
    "        elif pd.notnull(date_employment):\n",
    "            return date_employment.date()\n",
    "        else:\n",
    "            return np.nan\n",
    "    elif attr in ['street_address', 'suburb', 'postcode', 'state']:\n",
    "        # Use the most recent address based on event dates\n",
    "        date_medical_str = row.get('consultation_timestamp', np.nan)\n",
    "        date_employment_str = row.get('employment_timestamp', np.nan)\n",
    "        date_medical = parse_date_with_24_hour(date_medical_str)\n",
    "        date_employment = parse_date_with_24_hour(date_employment_str)\n",
    "        if pd.notnull(date_medical) and pd.notnull(date_employment):\n",
    "            if date_medical >= date_employment:\n",
    "                return val_medical\n",
    "            else:\n",
    "                return val_employment\n",
    "        elif pd.notnull(date_medical):\n",
    "            return val_medical\n",
    "        elif pd.notnull(date_employment):\n",
    "            return val_employment\n",
    "        else:\n",
    "            # If dates are not available, use the non-null value\n",
    "            return val_medical if val_medical_std else val_employment\n",
    "    elif attr in ['phone', 'email']:\n",
    "        # Combine contact methods into a list, removing duplicates\n",
    "        contacts = set()\n",
    "        if val_medical_std:\n",
    "            contacts.add(val_medical)\n",
    "        if val_employment_std:\n",
    "            contacts.add(val_employment)\n",
    "        # Return combined contacts separated by semicolon\n",
    "        return '; '.join(contacts)\n",
    "    else:\n",
    "        # For other attributes, prefer non-null over null\n",
    "        return val_medical if val_medical_std else val_employment\n",
    "\n",
    "# Apply the resolution function to each attribute\n",
    "for attr in attributes_to_resolve:\n",
    "    merged_dataset[attr] = merged_dataset.apply(lambda row: resolve_attribute(row, attr), axis=1)\n",
    "    \n",
    "    # Drop the individual columns from medical and employment datasets\n",
    "    attr_medical = attr + '_medical'\n",
    "    attr_employment = attr + '_employment'\n",
    "    if attr_medical in merged_dataset.columns:\n",
    "        merged_dataset.drop(columns=[attr_medical], inplace=True)\n",
    "    if attr_employment in merged_dataset.columns:\n",
    "        merged_dataset.drop(columns=[attr_employment], inplace=True)\n",
    "\n",
    "# Handle additional attributes unique to each dataset\n",
    "# Keep other attributes from medical dataset\n",
    "medical_attrs = [col for col in medical_dataset.columns if col not in ['ssn'] + attributes_to_resolve]\n",
    "# Keep other attributes from employment dataset\n",
    "employment_attrs = [col for col in employment_dataset.columns if col not in ['ssn'] + attributes_to_resolve]\n",
    "\n",
    "# For attributes unique to each dataset, ensure they are included in the merged dataset\n",
    "for attr in medical_attrs:\n",
    "    attr_medical = attr + '_medical'\n",
    "    if attr_medical in merged_dataset.columns:\n",
    "        merged_dataset[attr] = merged_dataset[attr_medical]\n",
    "        merged_dataset.drop(columns=[attr_medical], inplace=True)\n",
    "    elif attr in merged_dataset.columns:\n",
    "        continue\n",
    "    else:\n",
    "        merged_dataset[attr] = np.nan\n",
    "\n",
    "for attr in employment_attrs:\n",
    "    attr_employment = attr + '_employment'\n",
    "    if attr_employment in merged_dataset.columns:\n",
    "        merged_dataset[attr] = merged_dataset[attr_employment]\n",
    "        merged_dataset.drop(columns=[attr_employment], inplace=True)\n",
    "    elif attr in merged_dataset.columns:\n",
    "        continue\n",
    "    else:\n",
    "        merged_dataset[attr] = np.nan\n",
    "\n",
    "# Now, merged_dataset contains resolved attributes and all other attributes\n",
    "# You can save the cleaned and merged dataset to a new CSV file\n",
    "merged_dataset.to_csv('merged_dataset_cleaned.csv', index=False)\n",
    "\n",
    "# Optionally, display a sample of the cleaned dataset\n",
    "print(\"\\nSample of the cleaned and merged dataset:\")\n",
    "print(merged_dataset.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
